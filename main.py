import streamlit as st
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_history_aware_retriever
from langchain_openai import ChatOpenAI
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from dotenv import load_dotenv
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory
import re
from datetime import datetime

# Load environment variables (like OpenAI API keys, etc.)
load_dotenv()


# Function to retrieve programs based on query
def get_retriever(persist_directory="./db"):
    vectorstore = Chroma(
        persist_directory=persist_directory,
        embedding_function=OpenAIEmbeddings(model='text-embedding-3-small')
    )
    return vectorstore.as_retriever(search_kwargs={"k": 5})


# Function to initialize components and setup retriever and prompts
retriever = get_retriever()
llm = ChatOpenAI(model="gpt-4o-mini")


def initialize_components():
    today = datetime.today().strftime('%Y-%m-%d')
    # Define the contextualize question prompt
    contextualize_q_system_prompt = """
    #ì—­í• :
    ì±„íŒ… ê¸°ë¡ê³¼ ì§ˆë¬¸ì„ í† ëŒ€ë¡œ ëŒ€í™” ë‚´ì—­ ì—†ì´ë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ë…ë¦½ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ëŠ” ë´‡
    
    #ì§€ì‹œì‚¬í•­:
    ëŒ€í™” ë‚´ì—­ê³¼ ìµœì‹  ì‚¬ìš©ì ì§ˆë¬¸ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ ì‘ì„±
    ì§ˆë¬¸ì— ë‹µë³€í•˜ì§€ ë§ê³ , í•„ìš”í•˜ë©´ ì§ˆë¬¸ì„ ì¬êµ¬ì„±í•œ í›„ ê·¸ëŒ€ë¡œ ë°˜í™˜
    'ì˜¤ëŠ˜', 'ì´ë²ˆ ë‹¬', 'ì§€ê¸ˆ', 'ì´ë²ˆì£¼'ê³¼ ê°™ì€ ìƒëŒ€ì ì¸ ë‚ ì§œê°€ ìˆë‹¤ë©´, 'ì˜¤ëŠ˜'ì„ ê¸°ì¤€ìœ¼ë¡œ ë³€ê²½
    ì§ˆë¬¸ì— ë‚ ì§œê°€ ì–¸ê¸‰ë˜ì§€ ì•Šì•˜ë‹¤ë©´, 'ì˜¤ëŠ˜'ì„ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ 2ë‹¬ ì „ê¹Œì§€ë¥¼ ë¬¸ì˜í•˜ì„¸ìš”.
    
    #ì˜¤ëŠ˜: {today}
    
    #ì˜ˆì‹œ1
    ì±„íŒ…ê¸°ë¡:
    - ì‚¬ìš©ì: "2024ë…„ 10ì›” í‰ì°½ ì—¬í–‰ì§€ì›ê¸ˆì— ëŒ€í•´ ì•Œë ¤ì¤˜"
    - ì–´ì‹œìŠ¤í„´íŠ¸: "A, B, C í”„ë¡œê·¸ë¨ì´ ìˆìŠµë‹ˆë‹¤."
    - ì‚¬ìš©ì : "ê·¸ ì¤‘ì—ì„œ ì•„ì´ì™€ í•¨ê»˜ í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨ì´ ë­ì•¼?"
    
    ë‹µë³€: "A, B, C í”„ë¡œê·¸ë¨ ì¤‘ì—ì„œ ì•„ì´ì™€ í•¨ê»˜ í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    
    #ì˜ˆì‹œ2
    ì±„íŒ…ê¸°ë¡:
    - ì‚¬ìš©ì: "ì „ë¼ë„ ì—¬í–‰ì§€ì›ê¸ˆì— ëŒ€í•´ ì•Œë ¤ì¤˜"
    
    ë‹µë³€: "{today} ì— ê°ˆ ìˆ˜ ìˆëŠ” ì „ë¼ë„ ì—¬í–‰ì§€ì›ê¸ˆì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”."    
    """.format(today=today)

    contextualize_q_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", contextualize_q_system_prompt),
            MessagesPlaceholder("history"),
            ("human", "{input}"),
        ]
    )

    # Define the answer question prompt
    qa_system_prompt = """
    #ì—­í• :
    ì§ˆë¬¸ì— ëŒ€í•´ ì—¬í–‰ì§€ì›ê¸ˆ í”„ë¡œê·¸ë¨ì„ ì°¾ì•„ì£¼ëŠ” ë´‡
    
    #ì§€ì‹œì‚¬í•­:
    - ë‹µë³€ì€ ì•„ë˜ì˜ 'ë‹µë³€ í˜•ì‹'ì— ë§ì¶”ì–´ ì‘ì„±í•˜ì‹­ì‹œì˜¤. ë‹¨, í”„ë¡œê·¸ë¨ì— ëŒ€í•´ ì„¤ëª…í•´ë‹¬ë¼ëŠ” ì§ˆë¬¸ì´ ìˆì„ ê²½ìš°, ë‹µë³€ í˜•ì‹ì„ ë¬´ì‹œí•˜ê³  í•´ë‹¹ í”„ë¡œê·¸ë¨ì— ëŒ€í•œ ì„¤ëª…ì„ í•´ì£¼ì‹­ì‹œì˜¤.
    - ë‹¤ìŒì˜ ì°¸ê³ í•  í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì‹­ì‹œì˜¤.
    - ì§ˆë¬¸ê³¼ ì£¼ì–´ì§„ context ì˜ ì§€ì—­(ê´‘ì—­ì‹œ/ë„, ì‹œ/êµ°/êµ¬)ì´ ë‹¤ë¥¸ ê²½ìš° ì§ˆë¬¸ì˜ ë‹µìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
    - ì§€ì—­ì´ ëª…ì‹œë˜ì§€ ì•Šì€ ê²½ìš° ëª¨ë“  context ë¥¼ ì§ˆë¬¸ì˜ ë‹µìœ¼ë¡œ í™œìš©í•˜ì‹­ì‹œì˜¤. 
    - ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ í•˜ê³ , ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
    - ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ìˆë‹¤ë©´ ë‹µë³€ì˜ ë§ˆì§€ë§‰ì— 'ìì„¸í•œ ì‚¬í•­ì€ ë§í¬ë¥¼ í†µí•´ í™•ì¸í•˜ì„¸ìš”' ë¬¸êµ¬ì™€ ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.
    - ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì´ ì—†ë‹¤ë©´ ë‹µë³€ì˜ ë§ˆì§€ë§‰ì— ë§í¬ë¥¼ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
    
    #ì œì•½:
    - íŠ¹ì • ë‚ ì§œê°€ ë‚˜ì˜¤ë©´ í™œë™ ì‹œì‘ ì‹œê°„ ~ í™œë™ ì¢…ë£Œ ì‹œê°„ìœ¼ë¡œ íŒë‹¨í•˜ì‹­ì‹œì˜¤.
    - 'ë‹µë³€ í˜•ì‹1'ì€ ìµœëŒ€ 3ê°œ í”„ë¡œê·¸ë¨ìœ¼ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    - ì—°ê´€ëœ í”„ë¡œê·¸ë¨ì´ 2ê°œ ì´ìƒì´ë¼ë©´ 2ê°œ ì´ìƒ ëª¨ë‘ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
    - í”„ë¡œê·¸ë¨ì˜ ì„¸ë¶€ì‚¬í•­ì´ ë‹¤ë¥´ë‹¤ë©´ í•´ë‹¹ í”„ë¡œê·¸ë¨ì„ ë‹µë³€ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜ˆë¥¼ ë“¤ì–´ì„œ ì•„ì´ì™€ ê°ˆ ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë¨ì„ ë¬¼ì–´ë´¤ì„ ë•Œ 'ì•„ì´ ë™ë°˜ ì—¬ë¶€'ëŠ” ê°€ëŠ¥ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.
    - ì•Œë§ì€ í”„ë¡œê·¸ë¨ì´ ì—†ëŠ” ê²½ìš°, í•´ë‹¹í•˜ëŠ” í”„ë¡œê·¸ë¨ì´ ì—†ë‹¤ê³  ë‹µë³€í•˜ì‹­ì‹œì˜¤.
    
    #ì£¼ìš” key í•´ì„
    í™œë™ ì‹œì‘ ì‹œê°„: ì—¬í–‰, í™œë™ì„ ì‹œì‘í•˜ëŠ” ë‚ ì§œì…ë‹ˆë‹¤.
    í™œë™ ì¢…ë£Œ ì‹œê°„: ì—¬í–‰, í™œë™ì„ ì¢…ë£Œí•˜ëŠ” ë‚ ì§œì…ë‹ˆë‹¤.
    ìµœëŒ€ í™œë™(ì—¬í–‰)ì¼ìˆ˜: ì—¬í–‰, í™œë™ì„ ìµœëŒ€ë¡œ í•  ìˆ˜ ìˆëŠ” ì¼ìˆ˜ì…ë‹ˆë‹¤.
    ìµœì†Œ í™œë™(ì—¬í–‰)ì¼ìˆ˜: ì—¬í–‰, í™œë™ì„ ìµœì†Œë¡œ í•  ìˆ˜ ìˆëŠ” ì¼ìˆ˜ì…ë‹ˆë‹¤.
    ê³µê³ (ì§€ì›) ë§ˆê° ì‹œê°„: ì‚¬ìš©ìê°€ í”„ë¡œê·¸ë¨ì— ì§€ì›í•˜ëŠ” ë§ˆê° ì‹œê°„ì…ë‹ˆë‹¤.
    ê³µê³ (ì§€ì›) ì‹œì‘ ì‹œê°„: ì‚¬ìš©ìê°€ í”„ë¡œê·¸ë¨ì— ì§€ì›í•˜ëŠ” ì‹œì‘ ì‹œê°„ì…ë‹ˆë‹¤.
    ì•„ì´ ë™ë°˜ ê°€ëŠ¥(ì•„ì´ í•¨ê»˜ ê°€ê¸°): ì•„ì´ì™€ í•¨ê»˜ ì—¬í–‰ì„ í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤.
    ì•„ì´ ì§€ì›ê¸ˆ ì§€ì› ì—¬ë¶€: í”„ë¡œê·¸ë¨ì—ì„œ ì•„ì´ì—ê²Œ ì§€ì›ê¸ˆì„ ì§€ì›í•˜ëŠ”ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤.
    ë°˜ë ¤ë™ë¬¼ ë™ë°˜ ê°€ëŠ¥ ì—¬ë¶€: ë°˜ë ¤ë™ë¬¼ì„ ë™ë°˜í•  ìˆ˜ ìˆëŠ”ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤.
    ìœ ë£Œ í”„ë¡œê·¸ë¨ ì—¬ë¶€: í”„ë¡œê·¸ë¨ì´ ìœ ë£Œì¸ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ìœ ë£Œì¸ ê²½ìš°, ì°¸ê°€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    ì„ ì°©ìˆœ ì—¬ë¶€: í”„ë¡œê·¸ë¨ì„ ì§€ì›í•  ë•Œ ì„ ì°©ìˆœì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.
    ì „ì•¡ ì§€ì› ì—¬ë¶€: í”„ë¡œê·¸ë¨ì„ ì „ì•¡ ì§€ì›í•˜ëŠ”ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤. ì§€ì›ê¸ˆ ë†’ì€ ìˆœì„ ì§ˆë¬¸í•  ë•Œ í•­ìƒ ì „ì•¡ ì§€ì›ì´ ìš°ì„ í•©ë‹ˆë‹¤.
   
    #ë‹µë³€ í˜•ì‹:\n
    - 1ë²ˆ í”„ë¡œê·¸ë¨\n
      - í”„ë¡œê·¸ë¨ ì œëª©: 00 í•œë‹¬ì‚´ê¸°\n
      - í”„ë¡œê·¸ë¨ ë‚´ìš©: 00ì—ì„œ í•œë‹¬ì‚´ê¸°ë¥¼ í•˜ëŠ” í”„ë¡œê·¸ë¨ì…ë‹ˆë‹¤. ìˆ™ë°•ë¹„ê°€ ì§€ì›ë©ë‹ˆë‹¤.\n
      - í™œë™ ì‹œì‘ ì‹œê°„: 2024-01-26\n
      - í™œë™ ì¢…ë£Œ ì‹œê°„: 2024-02-10\n
      - ê³µê³ (ì§€ì›) ì‹œì‘ ì‹œê°„: 2024-01-01\n
      - ê³µê³ (ì§€ì›) ë§ˆê° ì‹œê°„: 2024-01-10\n
      - í•œë‹¬ì‚´ëŸ¬ ë§í¬: https://www.monthler.kr/programs/12\n
    ---\n
    - 2ë²ˆ í”„ë¡œê·¸ë¨\n
      - í”„ë¡œê·¸ë¨ ì œëª©: 2024 00 ìŠ¤íƒ¬í”„ íˆ¬ì–´\n
      - í”„ë¡œê·¸ë¨ ë‚´ìš©: 00ì—ì„œ ìŠ¤íƒ¬í”„ íˆ¬ì–´ë¥¼ í•˜ê³  ì§€ì›ê¸ˆì„ ë°›ìœ¼ì„¸ìš”.\n
      - í™œë™ ì‹œì‘ ì‹œê°„: 2024-03-01\n
      - í™œë™ ì¢…ë£Œ ì‹œê°„: 2024-04-20\n
      - ê³µê³ (ì§€ì›) ì‹œì‘ ì‹œê°„: 2024-02-01\n
      - ê³µê³ (ì§€ì›) ë§ˆê° ì‹œê°„: 2024-02-15\n
      - í•œë‹¬ì‚´ëŸ¬ ë§í¬: https://www.monthler.kr/programs/672\n
    ---\n
    - 3ë²ˆ í”„ë¡œê·¸ë¨\n
      - í”„ë¡œê·¸ë¨ ì œëª©: 00ì—ì„œ ìº í•‘í•˜ì\n
      - í”„ë¡œê·¸ë¨ ë‚´ìš©: 00ì—ì„œ ìº í•‘ì„ í•˜ê³  ì§€ì›ê¸ˆì„ ë°›ìœ¼ì„¸ìš”.\n
      - í™œë™ ì‹œì‘ ì‹œê°„: 2024-05-01\n
      - í™œë™ ì¢…ë£Œ ì‹œê°„: 2024-05-10\n
      - ê³µê³ (ì§€ì›) ì‹œì‘ ì‹œê°„: 2024-04-01\n
      - ê³µê³ (ì§€ì›) ë§ˆê° ì‹œê°„: 2024-04-15\n
      - í•œë‹¬ì‚´ëŸ¬ ë§í¬: https://www.monthler.kr/programs/45\n
   
    #ì°¸ê³ í•  í”„ë¡œê·¸ë¨ ì •ë³´:
    {context}"""
    qa_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", qa_system_prompt),
            MessagesPlaceholder("history"),
            ("human", "{input}"),
        ]
    )

    history_aware_retriever = create_history_aware_retriever(llm, retriever, contextualize_q_prompt)
    question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)
    return create_retrieval_chain(history_aware_retriever, question_answer_chain)


# Main function to handle user input and output
st.header("ì—¬í–‰ì§€ì›ê¸ˆ Q&A ì±—ë´‡ ğŸ’¬ ğŸ“š")

rag_chain = initialize_components()
chat_history = StreamlitChatMessageHistory(key="chat_messages")

conversational_rag_chain = RunnableWithMessageHistory(
    rag_chain,
    lambda session_id: chat_history,
    input_messages_key="input",
    history_messages_key="history",
    output_messages_key="answer",
)

# Initialize session state for messages
if "messages" not in st.session_state:
    st.chat_message("assistant").write("ì—¬í–‰ì§€ì›ê¸ˆì„ ê²€ìƒ‰í•˜ì„¸ìš”!")

# Display previous messages from session state
for msg in chat_history.messages:
    st.chat_message(msg.type).write(msg.content)

# Process user input
if prompt_message := st.chat_input("Your question"):
    # Store user's message in session state
    st.chat_message("human").write(prompt_message)

    # Perform search and display results
    with st.chat_message("assistant"):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            config = {"configurable": {"session_id": "any"}}
            response = conversational_rag_chain.invoke(
                {"input": prompt_message},
                config)

            answer = response['answer']
            st.write(answer)